{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDA+AZafrI5qgZkRxVA8+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romaindujardin/SPOT/blob/main/Pipeline_SPOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SPOT"
      ],
      "metadata": {
        "id": "IjbM1GrN_-Xo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importation des bibliothèques"
      ],
      "metadata": {
        "id": "KWLEnwHRF4Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "ZhKrf6dtFzRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accès au drive"
      ],
      "metadata": {
        "id": "8Md-QVAsAA7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monter le Google Drive (si ce n'est pas déjà fait)\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jLEmh_R3_dOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importation du dataset"
      ],
      "metadata": {
        "id": "Peb5kRPt_4aY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ROOT = \"/content/drive/My Drive/Colab Notebooks/DATASET\"\n",
        "\n",
        "# Vérification immédiate\n",
        "if os.path.exists(DATASET_ROOT):\n",
        "    print(f\"Dossier DATASET trouvé à : {DATASET_ROOT}\")\n",
        "    classes_trouvees = os.listdir(DATASET_ROOT)\n",
        "    print(f\"Dossiers élèves détectés ({len(classes_trouvees)}) : {classes_trouvees[:5]} ...\")\n",
        "else:\n",
        "    print(f\"ERREUR : Le dossier n'est pas trouvé à : {DATASET_ROOT}\")\n",
        "    print(\"Vérifie le chemin dans la variable DATASET_ROOT ci-dessus.\")"
      ],
      "metadata": {
        "id": "npSEElW-_3w6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition de la structure classes et professeurs"
      ],
      "metadata": {
        "id": "p0yY9aYzCKYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a donc dans le dataset la liste complète avec photo de chaque élève via cette forme\n",
        "\n",
        "```\n",
        "Eleve 1/\n",
        "        Photo1.png\n",
        "        Photo2.png\n",
        "Eleve 2/\n",
        "        Photo1.png\n",
        "        Photo2.png\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "wLWd6rQfl4fb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Et à présent on défini les classes, tel élève est dans tel classe et on affecte les classes au professeur"
      ],
      "metadata": {
        "id": "IJonhx6PmTkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On initialise la variable ici pour qu'elle existe même avant le clic\n",
        "global ELEVES_ATTENDUS\n",
        "ELEVES_ATTENDUS = []\n",
        "\n",
        "# Structure\n",
        "ecole_structure = {\n",
        "    \"Professeur A\": {\n",
        "        \"IA\": [\"romain\", \"laurence\", \"Eleve_IA_3\", \"Eleve_IA_4\", \"Eleve_IA_5\"],\n",
        "        \"Cyber\": [\"Eleve_Cy_1\", \"Eleve_Cy_2\", \"Eleve_Cy_3\", \"Eleve_Cy_4\", \"Eleve_Cy_5\"]\n",
        "    },\n",
        "    \"Professeur B\": {\n",
        "        \"IA\": [\"Eleve_IA_1\", \"Eleve_IA_2\", \"Eleve_IA_3\", \"Eleve_IA_4\", \"Eleve_IA_5\"],\n",
        "        \"Cyber\": [\"Eleve_Cy_1\", \"Eleve_Cy_2\", \"Eleve_Cy_3\", \"Eleve_Cy_4\", \"Eleve_Cy_5\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n--- SÉLECTION DU COURS ---\")\n",
        "prof_dropdown = widgets.Dropdown(options=ecole_structure.keys(), description='Prof:')\n",
        "classe_dropdown = widgets.Dropdown(description='Classe:')\n",
        "btn_select = widgets.Button(description=\"Charger la classe\", button_style='success')\n",
        "output = widgets.Output()\n",
        "\n",
        "# Mise à jour des listes déroulantes\n",
        "def update_classes(change):\n",
        "    classe_dropdown.options = ecole_structure[change.new].keys()\n",
        "prof_dropdown.observe(update_classes, names='value')\n",
        "classe_dropdown.options = ecole_structure[prof_dropdown.value].keys()\n",
        "\n",
        "def on_button_click(b):\n",
        "    global ELEVES_ATTENDUS # <--- C'EST ICI LA CORRECTION IMPORTANTE\n",
        "    with output:\n",
        "        clear_output()\n",
        "        prof = prof_dropdown.value\n",
        "        classe = classe_dropdown.value\n",
        "\n",
        "        # On remplit la variable globale\n",
        "        ELEVES_ATTENDUS = ecole_structure[prof][classe]\n",
        "\n",
        "        print(f\"Cours : {prof} - Classe {classe}\")\n",
        "        print(f\"Élèves chargés : {ELEVES_ATTENDUS}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Vérif rapide\n",
        "        DATASET_ROOT = \"/content/drive/My Drive/Colab Notebooks/DATASET\"\n",
        "        if os.path.exists(DATASET_ROOT):\n",
        "            missings = [e for e in ELEVES_ATTENDUS if not os.path.exists(os.path.join(DATASET_ROOT, e))]\n",
        "            if not missings:\n",
        "                print(\"Tous les dossiers élèves sont présents.\")\n",
        "            else:\n",
        "                print(f\"Manquants dans le Drive : {missings}\")\n",
        "\n",
        "btn_select.on_click(on_button_click)\n",
        "display(prof_dropdown, classe_dropdown, btn_select, output)"
      ],
      "metadata": {
        "id": "usZb1vv89AxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Si besoin réparation du dataset (bonne convertion image en jpg etc)"
      ],
      "metadata": {
        "id": "iuWT5eOECgXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On regarde que le format des images soit bien .png si c'est pas le cas on transforme"
      ],
      "metadata": {
        "id": "TyUh2HKtmfBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Installer la librairie pour lire le format HEIC (iPhone)\n",
        "!pip install pillow-heif\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "from pillow_heif import register_heif_opener\n",
        "\n",
        "# Enregistre le lecteur HEIF pour que PIL puisse comprendre tes fichiers\n",
        "register_heif_opener()\n",
        "\n",
        "# Ton dossier dataset (Assure-toi que c'est le bon chemin)\n",
        "dataset_path = \"/content/drive/My Drive/Colab Notebooks/DATASET\"\n",
        "\n",
        "print(\"Démarrage de la réparation des images...\")\n",
        "\n",
        "# On parcourt tous les dossiers (romain, etc.)\n",
        "for root, dirs, files in os.walk(dataset_path):\n",
        "    for file in files:\n",
        "        file_path = os.path.join(root, file)\n",
        "\n",
        "        # On ne traite que les fichiers qui finissent par jpg, jpeg, png ou heic\n",
        "        if file.lower().endswith(('.jpg', '.jpeg', '.png', '.heic')):\n",
        "            try:\n",
        "                # On essaie d'ouvrir l'image\n",
        "                img = Image.open(file_path)\n",
        "\n",
        "                # On force la conversion en RGB (car le JPG ne supporte pas la transparence)\n",
        "                img = img.convert(\"RGB\")\n",
        "\n",
        "                # On sauvegarde par dessus en forçant le format JPEG\n",
        "                # Si le fichier s'appelait .heic, on peut changer son extension ici si on veut,\n",
        "                # mais comme tu les as déjà renommés en .jpg, on écrase simplement le fichier.\n",
        "                img.save(file_path, \"JPEG\")\n",
        "\n",
        "                print(f\"✅ Réparé/Converti : {file}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erreur sur {file} : {e}\")\n",
        "\n",
        "print(\"\\nRéparation terminée ! Tu peux relancer l'entraînement (Étape 3).\")"
      ],
      "metadata": {
        "id": "hw6nxrupA0CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### On prends chaque image du dataset et on recadre pour obtenir uniquement une image avec le visage sans background"
      ],
      "metadata": {
        "id": "BiI9s24fgFIH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "cela permets que lors de l'entrainement le modele apres à reconnaitre uniquement le visage et pas le background qui va avec un visage. (si fond blanc alors c'est le visage A car les images du dataset sont sur fond blanc)"
      ],
      "metadata": {
        "id": "KV0jCKfgmmED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Où sont tes photos originales (Sur le Drive)\n",
        "DRIVE_SOURCE_PATH = \"/content/drive/My Drive/Colab Notebooks/DATASET\"\n",
        "\n",
        "# Où on va travailler dans Colab (Rapide / Temporaire)\n",
        "LOCAL_RAW_DIR = \"/content/dataset\"       # Copie des originaux\n",
        "LOCAL_CROP_DIR = \"/content/dataset_crop\"    # Résultat recadré\n",
        "\n",
        "# --- ÉTAPE 1 : COPIE DRIVE -> LOCAL ---\n",
        "print(f\"COPIE : Drive -> Colab Local...\")\n",
        "if not os.path.exists(DRIVE_SOURCE_PATH):\n",
        "    print(f\"ERREUR : Le dossier {DRIVE_SOURCE_PATH} n'existe pas !\")\n",
        "else:\n",
        "    # On nettoie si ça existe déjà pour repartir de zéro\n",
        "    if os.path.exists(LOCAL_RAW_DIR):\n",
        "        shutil.rmtree(LOCAL_RAW_DIR)\n",
        "\n",
        "    # Copie du dossier complet\n",
        "    shutil.copytree(DRIVE_SOURCE_PATH, LOCAL_RAW_DIR)\n",
        "    print(\"Copie terminée sur le disque rapide.\")\n",
        "\n",
        "    # --- ÉTAPE 2 : RECADRAGE (Ta moulinette) ---\n",
        "    print(f\"\\nDÉMARRAGE DU RECADRAGE...\")\n",
        "\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "\n",
        "    # Création du dossier de destination local\n",
        "    if os.path.exists(LOCAL_CROP_DIR):\n",
        "        shutil.rmtree(LOCAL_CROP_DIR)\n",
        "    os.makedirs(LOCAL_CROP_DIR)\n",
        "\n",
        "    total_images = 0\n",
        "    total_faces = 0\n",
        "\n",
        "    classes = [d for d in os.listdir(LOCAL_RAW_DIR) if os.path.isdir(os.path.join(LOCAL_RAW_DIR, d))]\n",
        "\n",
        "    for classe in classes:\n",
        "        src_folder = os.path.join(LOCAL_RAW_DIR, classe)\n",
        "        dst_folder = os.path.join(LOCAL_CROP_DIR, classe)\n",
        "\n",
        "        os.makedirs(dst_folder, exist_ok=True)\n",
        "        print(f\"Classe : {classe}\")\n",
        "\n",
        "        for file_name in os.listdir(src_folder):\n",
        "            if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                total_images += 1\n",
        "                img_path = os.path.join(src_folder, file_name)\n",
        "                img = cv2.imread(img_path)\n",
        "\n",
        "                if img is None: continue\n",
        "\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                # Paramètres ajustés pour être un peu plus permissifs (scaleFactor 1.1, minNeighbors 4)\n",
        "                faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "                if len(faces) > 0:\n",
        "                    # On prend le plus grand visage\n",
        "                    (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])\n",
        "\n",
        "                    # Marge de sécurité pour ne pas couper trop serré\n",
        "                    margin = 30\n",
        "                    x = max(0, x - margin)\n",
        "                    y = max(0, y - margin)\n",
        "                    w = min(img.shape[1] - x, w + 2*margin)\n",
        "                    h = min(img.shape[0] - y, h + 2*margin)\n",
        "\n",
        "                    face_crop = img[y:y+h, x:x+w]\n",
        "\n",
        "                    save_path = os.path.join(dst_folder, file_name)\n",
        "                    cv2.imwrite(save_path, face_crop)\n",
        "                    total_faces += 1\n",
        "                else:\n",
        "                    print(f\" Pas de visage : {file_name}\")\n",
        "\n",
        "    print(f\"\\nRECADRAGE TERMINÉ : {total_faces}/{total_images} visages extraits.\")\n",
        "\n",
        "    print(f\"\\nDataset propre sauvegardé localement dans : {LOCAL_CROP_DIR}\")"
      ],
      "metadata": {
        "id": "S0jh5Q108cKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement du modèle sur le dataset"
      ],
      "metadata": {
        "id": "4_6vBKbACikA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Configuration\n",
        "DATASET_ROOT = \"/content/dataset_crop\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 8\n",
        "\n",
        "# MODIFICATION 1 : DATA AUGMENTATION\n",
        "# On crée des variations artificielles pour empêcher le \"par cœur\"\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),      # Effet miroir (1 fois sur 2)\n",
        "    transforms.RandomRotation(15),               # Rotation légère (-15° à +15°)\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2), # Changement de lumière\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Chargement du dataset avec les transformations\n",
        "if os.path.exists(DATASET_ROOT):\n",
        "    full_dataset = datasets.ImageFolder(root=DATASET_ROOT, transform=train_transform)\n",
        "    class_names = full_dataset.classes\n",
        "    print(f\"Classes (Élèves) détectées : {class_names}\")\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # MODIFICATION 2 : TRANSFER LEARNING ROBUSTE\n",
        "    # On charge un ResNet pré-entraîné\n",
        "    model = models.resnet18(pretrained=True)\n",
        "\n",
        "    # ON GÈLE (FREEZE) les couches existantes\n",
        "    # Le modèle garde son intelligence \"générale\" (bords, formes, yeux, nez...)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # On ne remplace et n'entraîne QUE la dernière couche (le classificateur)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, len(class_names))\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Entraînement\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # On optimise SEULEMENT la dernière couche (model.fc)\n",
        "    optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "    print(\"Démarrage de l'entraînement robuste...\")\n",
        "    # On augmente un peu les époques car c'est plus dur d'apprendre avec l'augmentation\n",
        "    epochs = 15\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Calcul précision immédiate\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = 100 * correct / total\n",
        "\n",
        "        # On affiche un log un peu plus détaillé\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.1f}%\")\n",
        "\n",
        "    # Sauvegarde\n",
        "    torch.save(model.state_dict(), \"spot_model.pth\")\n",
        "    print(\"Modèle SPOT (Robuste) sauvegardé sous 'spot_model.pth'\")\n",
        "\n",
        "else:\n",
        "    print(\"ERREUR : DATASET_ROOT introuvable. Vérifie le chemin.\")"
      ],
      "metadata": {
        "id": "iOfruFZy9My-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline SPOT"
      ],
      "metadata": {
        "id": "7mRkbIX9Cl-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importation des bibliothèques"
      ],
      "metadata": {
        "id": "vTUVlYxrDODL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Javascript, clear_output\n",
        "from google.colab.output import eval_js\n",
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "p56xvW78DNCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuration des variables"
      ],
      "metadata": {
        "id": "fHYzfNjWC7ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration des variables\n",
        "BUFFER_TIME = 5.0"
      ],
      "metadata": {
        "id": "KetK-HkMDl1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement du modèle"
      ],
      "metadata": {
        "id": "UW6CWT8MQLRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du modèle entrainé\n",
        "if os.path.exists(DATASET_ROOT):\n",
        "    class_names = sorted(os.listdir(DATASET_ROOT))\n",
        "else:\n",
        "    class_names = [\"Inconnu\"]\n",
        "\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"spot_model.pth\", map_location=device))\n",
        "except:\n",
        "    pass\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "metadata": {
        "id": "10P0f8k8DFu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interface et lancement du cours"
      ],
      "metadata": {
        "id": "SExY_r6ZHWXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Si la confiance est inférieure à 70%, on considère que c'est \"Inconnu\"\n",
        "SEUIL_CONFIANCE = 0.70\n",
        "\n",
        "# Javascript pour la caméra\n",
        "js_camera = \"\"\"\n",
        "    if (!document.getElementById('videoElement')) {\n",
        "        var video = document.createElement('video');\n",
        "        video.id = 'videoElement';\n",
        "        video.style.display = 'none';\n",
        "        document.body.appendChild(video);\n",
        "        var canvas = document.createElement('canvas');\n",
        "        canvas.id = 'canvasElement';\n",
        "        canvas.style.display = 'none';\n",
        "        document.body.appendChild(canvas);\n",
        "    }\n",
        "    async function stream_frame() {\n",
        "        var video = document.getElementById('videoElement');\n",
        "        var canvas = document.getElementById('canvasElement');\n",
        "        if (video.paused) {\n",
        "            var stream = await navigator.mediaDevices.getUserMedia({video: {width: 640, height: 480}});\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "        }\n",
        "        canvas.width = video.videoWidth;\n",
        "        canvas.height = video.videoHeight;\n",
        "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "        return canvas.toDataURL('image/jpeg', 0.6);\n",
        "    }\n",
        "\"\"\"\n",
        "display(Javascript(js_camera))\n",
        "\n",
        "def js_to_image(js_reply):\n",
        "    image_bytes = base64.b64decode(js_reply.split(',')[1])\n",
        "    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "    img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "    return img\n",
        "\n",
        "def format_time(seconds):\n",
        "    m, s = divmod(int(seconds), 60)\n",
        "    return f\"{m:02d}:{s:02d}\"\n",
        "\n",
        "# Variables pour le rapport\n",
        "global db_eleves_session, start_time_session, end_time_session\n",
        "db_eleves_session = {\n",
        "    eleve: {'first_seen': None, 'last_seen': None, 'status': 'ABSENT'}\n",
        "    for eleve in ELEVES_ATTENDUS\n",
        "}\n",
        "start_time_session = time.time()\n",
        "end_time_session = None\n",
        "\n",
        "# Interface\n",
        "header_widget = widgets.HTML(\"<h2>Initialisation...</h2>\")\n",
        "video_widget = widgets.Image(format='jpeg', width=500, height=375)\n",
        "status_widget = widgets.HTML(value=\"\", layout=widgets.Layout(width='400px', height='375px', border='1px solid #ccc', overflow='auto', padding='5px'))\n",
        "\n",
        "print(f\"COURS DÉMARRÉ. Seuil de confiance : {SEUIL_CONFIANCE * 100}%\")\n",
        "display(header_widget)\n",
        "display(widgets.HBox([video_widget, status_widget]))\n",
        "\n",
        "# Boucle\n",
        "try:\n",
        "    while True:\n",
        "        current_time = time.time()\n",
        "        duree_cours = current_time - start_time_session\n",
        "        header_widget.value = f\"<h2 style='color:#fff;'>DURÉE DU COURS : {format_time(duree_cours)}</h2>\"\n",
        "\n",
        "        js_reply = eval_js('stream_frame()')\n",
        "        frame = js_to_image(js_reply)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "        display_frame = frame.copy()\n",
        "\n",
        "        detected_in_frame = []\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Préparation de l'image visage pour le modèle\n",
        "            face_roi = frame[y:y+h, x:x+w]\n",
        "            face_pil = PIL.Image.fromarray(cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB))\n",
        "            img_tensor = transform(face_pil).unsqueeze(0).to(device)\n",
        "\n",
        "            # Prédiction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(img_tensor)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                score, pred = torch.max(probs, 1)\n",
        "\n",
        "            valeur_confiance = score.item() # ex: 0.85\n",
        "            pourcentage = int(valeur_confiance * 100) # ex: 85\n",
        "\n",
        "            # Par défaut : Inconnu / Rouge\n",
        "            color = (0, 0, 255) # Rouge (BGR)\n",
        "            name_label = f\"Inconnu ({pourcentage}%)\" # On affiche le % même si c'est inconnu\n",
        "\n",
        "            # --- LOGIQUE DE SEUIL ---\n",
        "            if valeur_confiance > SEUIL_CONFIANCE:\n",
        "                detected_name = class_names[pred.item()]\n",
        "\n",
        "                # Vérifie si cet élève est bien dans la classe attendue\n",
        "                if detected_name in db_eleves_session:\n",
        "                    detected_in_frame.append(detected_name)\n",
        "                    color = (0, 255, 0) # Vert\n",
        "                    # Mise à jour du label avec le pourcentage\n",
        "                    name_label = f\"{detected_name} {pourcentage}%\"\n",
        "\n",
        "                    # Mise à jour BDD Session\n",
        "                    db_eleves_session[detected_name]['last_seen'] = current_time\n",
        "                    if db_eleves_session[detected_name]['first_seen'] is None:\n",
        "                        db_eleves_session[detected_name]['first_seen'] = current_time\n",
        "                else:\n",
        "                    # C'est une tête connue du modèle, mais PAS de cette classe\n",
        "                    color = (0, 165, 255) # Orange\n",
        "                    name_label = f\"Intrus: {detected_name} ({pourcentage}%)\"\n",
        "\n",
        "            # Dessin\n",
        "            cv2.rectangle(display_frame, (x, y), (x+w, y+h), color, 2)\n",
        "            # Fond noir derrière le texte pour lisibilité\n",
        "            cv2.rectangle(display_frame, (x, y-35), (x+w, y), color, -1)\n",
        "            cv2.putText(display_frame, name_label, (x + 5, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
        "\n",
        "        # Tableau Dashboard (Même logique que précédemment)\n",
        "        html_content = \"<table style='width:100%; font-family:sans-serif; font-size:14px; border-collapse: collapse;'>\"\n",
        "        html_content += \"<tr style='background:#333; color:white;'><th style='padding:5px;'>Élève</th><th>Statut</th><th>Détails Chrono</th></tr>\"\n",
        "\n",
        "        for eleve in ELEVES_ATTENDUS:\n",
        "            data = db_eleves_session[eleve]\n",
        "            if data['first_seen'] is None:\n",
        "                status_txt = \"ABSENT\"\n",
        "                style = \"color:red;\"\n",
        "                retard = current_time - start_time_session\n",
        "                timer_txt = f\"En retard de : {format_time(retard)}\"\n",
        "            else:\n",
        "                time_since_last = current_time - data['last_seen']\n",
        "                retard_arrivee = data['first_seen'] - start_time_session\n",
        "                str_arrivee = f\"Arr: +{format_time(retard_arrivee)}\"\n",
        "\n",
        "                if time_since_last < BUFFER_TIME:\n",
        "                    status_txt = \"PRÉSENT\"\n",
        "                    style = \"color:green; font-weight:bold;\"\n",
        "                    timer_txt = str_arrivee\n",
        "                else:\n",
        "                    status_txt = \"PARTI\"\n",
        "                    style = \"color:orange; font-weight:bold;\"\n",
        "                    timer_txt = f\"Parti depuis : {format_time(time_since_last)}\"\n",
        "\n",
        "            html_content += f\"<tr style='border-bottom:1px solid #ddd; {style}'>\"\n",
        "            html_content += f\"<td style='padding:8px;'>{eleve}</td>\"\n",
        "            html_content += f\"<td style='text-align:center;'>{status_txt}</td>\"\n",
        "            html_content += f\"<td style='text-align:right; font-family:monospace;'>{timer_txt}</td></tr>\"\n",
        "\n",
        "        html_content += \"</table>\"\n",
        "        _, encoded_img = cv2.imencode('.jpg', display_frame)\n",
        "        video_widget.value = encoded_img.tobytes()\n",
        "        status_widget.value = html_content\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    end_time_session = time.time()\n",
        "    print(f\"\\nCours arrêté manuellement. Fin enregistrée à : {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Erreur : {e}\")"
      ],
      "metadata": {
        "id": "L-cOQ87fHLJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Génération du rapport final du cours"
      ],
      "metadata": {
        "id": "_LOmCtZc-89f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Vérification de sécurité (si on lance cette cellule sans avoir fait le cours)\n",
        "if 'end_time_session' not in globals() or end_time_session is None:\n",
        "    print(\"Attention : Le cours n'a pas été arrêté correctement ou n'a pas commencé.\")\n",
        "    end_time_session = time.time() # Valeur par défaut pour ne pas planter\n",
        "\n",
        "# Calcul sur la base du temps FIGÉ\n",
        "duree_totale_cours = end_time_session - start_time_session\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"RAPPORT DÉTAILLÉ SPOT - Fin du cours enregistrée\")\n",
        "print(f\"⏱Durée VALIDÉE du cours : {format_time(duree_totale_cours)}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "recap_data = []\n",
        "\n",
        "for eleve in ELEVES_ATTENDUS:\n",
        "    data = db_eleves_session[eleve]\n",
        "\n",
        "    retard_sec = 0.0\n",
        "    sortie_sec = 0.0\n",
        "    total_absence_sec = 0.0\n",
        "\n",
        "    col_retard = \"-\"\n",
        "    col_sortie = \"-\"\n",
        "    col_total = \"-\"\n",
        "    statut_final = \"ABSENT\"\n",
        "\n",
        "    # --- CALCULS ---\n",
        "    if data['first_seen'] is None:\n",
        "        # ABSENT TOUT LE LONG\n",
        "        statut_final = \"ABSENT\"\n",
        "        total_absence_sec = duree_totale_cours\n",
        "        col_total = format_time(total_absence_sec)\n",
        "        col_retard = \"Absent tout le cours\"\n",
        "        col_sortie = \"-\"\n",
        "\n",
        "    else:\n",
        "        # VENU AU MOINS UNE FOIS\n",
        "\n",
        "        # 1. Retard Début\n",
        "        retard_sec = data['first_seen'] - start_time_session\n",
        "        if retard_sec > 1.0:\n",
        "            col_retard = f\"+ {format_time(retard_sec)}\"\n",
        "        else:\n",
        "            col_retard = \"À l'heure\"\n",
        "            retard_sec = 0\n",
        "\n",
        "        # 2. Sortie Fin (Basé sur le temps figé end_time_session)\n",
        "        temps_depuis_derniere_vue = end_time_session - data['last_seen']\n",
        "\n",
        "        # Marge technique de 10s\n",
        "        if temps_depuis_derniere_vue < (BUFFER_TIME + 10.0):\n",
        "            statut_final = \"PRÉSENT\"\n",
        "            col_sortie = \"Non (Présent)\"\n",
        "            sortie_sec = 0\n",
        "        else:\n",
        "            statut_final = \"PARTI AVANT LA FIN\"\n",
        "            sortie_sec = temps_depuis_derniere_vue\n",
        "            col_sortie = f\"- {format_time(sortie_sec)}\"\n",
        "\n",
        "        # 3. Total\n",
        "        total_absence_sec = retard_sec + sortie_sec\n",
        "        col_total = format_time(total_absence_sec)\n",
        "\n",
        "    recap_data.append([eleve, statut_final, col_retard, col_sortie, col_total])\n",
        "\n",
        "df = pd.DataFrame(recap_data, columns=[\n",
        "    \"Élève\",\n",
        "    \"Statut Final\",\n",
        "    \"Retard (Début)\",\n",
        "    \"Sortie Anticipée (Fin)\",\n",
        "    \"Total Absence\"\n",
        "])\n",
        "\n",
        "# Styles\n",
        "def color_status(val):\n",
        "    if val == 'PRÉSENT': return 'color: green; font-weight: bold'\n",
        "    if val == 'ABSENT': return 'color: red; font-weight: bold'\n",
        "    if val == 'PARTI AVANT LA FIN': return 'color: orange; font-weight: bold'\n",
        "    return ''\n",
        "\n",
        "styles = [\n",
        "    dict(selector=\"th\", props=[(\"text-align\", \"center\")]),\n",
        "    dict(selector=\"td\", props=[(\"text-align\", \"center\")])\n",
        "]\n",
        "\n",
        "display(df.style.map(color_status, subset=['Statut Final']).set_table_styles(styles))"
      ],
      "metadata": {
        "id": "io_Ke-5UJbU3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}